==============================Classic================================

Step 1:
#log_0 train/validation
#log_2 validation

============DT=============
Train validation:
Precision: 0.990, recall: 0.999, F1-measure: 0.994
Test validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917

============LR=============
Train validation:
Precision: 0.983, recall: 0.999, F1-measure: 0.991
Test validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917

============SVM=============
Train validation:
Precision: 0.980, recall: 0.999, F1-measure: 0.989
Test validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917

============MultinomialNB/partial_fit=============
Train validation:
Precision: 0.935, recall: 0.921, F1-measure: 0.928
Test validation:
Precision: 0.909, recall: 0.833, F1-measure: 0.870

============Perceptron/partial_fit=============
Train validation:
Precision: 0.970, recall: 0.857, F1-measure: 0.910
Test validation:
Precision: 1.000, recall: 0.750, F1-measure: 0.857

============SGDC_SVM/partial_fit=============
Train validation:
Precision: 0.925, recall: 0.925, F1-measure: 0.925
Test validation:
Precision: 1.000, recall: 0.917, F1-measure: 0.957

============SGDC_LR/partial_fit=============
Train validation:
Precision: 0.840, recall: 0.933, F1-measure: 0.884
Test validation:
Precision: 0.706, recall: 1.000, F1-measure: 0.828

Step 2:
#log_1 validation

============DT=============
Test validation:
Precision: 0.985, recall: 0.998, F1-measure: 0.991

============LR=============
Test validation:
Precision: 0.974, recall: 0.998, F1-measure: 0.986

============SVM=============
Test validation:
Precision: 0.972, recall: 0.998, F1-measure: 0.985

============MultinomialNB/partial_fit=============
Test validation:
Precision: 0.928, recall: 0.919, F1-measure: 0.923

============Perceptron/partial_fit=============
Test validation:
Precision: 0.972, recall: 0.861, F1-measure: 0.913

============SGDC_SVM/partial_fit=============
Test validation:
Precision: 0.909, recall: 0.922, F1-measure: 0.915

============SGDC_LR/partial_fit=============
Test validation:
Precision: 0.844, recall: 0.924, F1-measure: 0.882

Step 3: partial_fit
#log_2 train/validation
#log_1 validation

============MultinomialNB/partial_fit=============
Train validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917
Test validation:
Precision: 0.931, recall: 0.944, F1-measure: 0.938

============Perceptron/partial_fit=============
Train validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917
Test validation:
Precision: 0.974, recall: 0.836, F1-measure: 0.900

============SGDC_SVM/partial_fit=============
Train validation:
Precision: 1.000, recall: 0.917, F1-measure: 0.957
Test validation:
Precision: 0.940, recall: 0.915, F1-measure: 0.927

============SGDC_LR/partial_fit=============
Train validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917
Test validation:
Precision: 0.918, recall: 0.850, F1-measure: 0.882

Step 4:
#log_3 validation

============DT=============
Test validation:
Precision: 1.000, recall: 0.325, F1-measure: 0.491

============LR=============
Test validation:
Precision: 1.000, recall: 0.297, F1-measure: 0.458

============SVM=============
Test validation:
Precision: 1.000, recall: 0.278, F1-measure: 0.435

============MultinomialNB/partial_fit=============
Test validation:
Precision: 1.000, recall: 0.040, F1-measure: 0.076

============Perceptron/partial_fit=============
Test validation:
Precision: 0.861, recall: 0.012, F1-measure: 0.023

============SGDC_SVM/partial_fit=============
Test validation:
Precision: 0.999, recall: 0.293, F1-measure: 0.454

============SGDC_LR/partial_fit=============
Test validation:
Precision: 1.000, recall: 0.377, F1-measure: 0.547

Step 5: partial_fit
#log_3 train/validation
#log_1 validation

============MultinomialNB/partial_fit=============
Train validation:
Precision: 0.980, recall: 1.000, F1-measure: 0.990
Test validation:
Precision: 0.850, recall: 0.964, F1-measure: 0.903

============Perceptron/partial_fit=============
Train validation:
Precision: 0.998, recall: 0.999, F1-measure: 0.999
Test validation:
Precision: 0.938, recall: 0.874, F1-measure: 0.905

============SGDC_SVM/partial_fit=============
Train validation:
Precision: 0.993, recall: 1.000, F1-measure: 0.996
Test validation:
Precision: 0.898, recall: 0.892, F1-measure: 0.895

============SGDC_LR/partial_fit=============
Train validation:
Precision: 0.999, recall: 0.990, F1-measure: 0.995
Test validation:
Precision: 0.897, recall: 0.933, F1-measure: 0.914

-------------------------top level scripts--------------------------------------

# han @ coffee in ~/Workspace/loganalyzer/entrance on git:develop x [22:29:15]
$ ./top_static_unix.sh
Pre-processing the raw train dataset ...
Purge costs 0:00:02.648125

===> Train Module: DecesionTree

The number of anomaly logs is 6663, but it requires further processing
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.062251

There are 395 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-395

Normal training...: DecesionTree

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001917

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed test data summary ======
Test data shape: 27-by-395

Train validation:
Precision: 0.990, recall: 0.999, F1-measure: 0.994

Test validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917

===> Train Module: LR

The number of anomaly logs is 6663, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.063191

There are 395 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-395

Normal training...: LR

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001990

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed test data summary ======
Test data shape: 27-by-395

Train validation:
Precision: 0.983, recall: 0.999, F1-measure: 0.991

Test validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917

===> Train Module: SVM

The number of anomaly logs is 6663, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.063339

There are 395 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-395

Normal training...: SVM

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.002045

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed test data summary ======
Test data shape: 27-by-395

Train validation:
Precision: 0.981, recall: 0.999, F1-measure: 0.990

Test validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917

Pre-processing the raw test dataset ...
Purge costs 0:00:01.539346

===> Predict Model: DecesionTree.onnx

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.035229

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-395

Test validation:
Precision: 0.985, recall: 0.998, F1-measure: 0.991

===> Predict Model: LR.onnx

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.036687

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-395

Test validation:
Precision: 0.974, recall: 0.998, F1-measure: 0.986

===> Predict Model: SVM.onnx

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.035133

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-395

Test validation:
Precision: 0.972, recall: 0.998, F1-measure: 0.985


# han @ coffee in ~/Workspace/loganalyzer/entrance on git:develop x [22:30:06]
$ ./top_pfit_unix.sh

===> Train Module: MultinomialNB

The number of anomaly logs is 6663, but it requires further processing
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.062033

There are 395 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: MultinomialNB

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001995

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed test data summary ======
Test data shape: 27-by-2000

Train validation:
Precision: 0.935, recall: 0.921, F1-measure: 0.928

Test validation:
Precision: 0.909, recall: 0.833, F1-measure: 0.870

===> Train Module: Perceptron

The number of anomaly logs is 6663, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.059532

There are 395 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: Perceptron

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.003329

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed test data summary ======
Test data shape: 27-by-2000

Train validation:
Precision: 0.868, recall: 0.892, F1-measure: 0.879

Test validation:
Precision: 0.733, recall: 0.917, F1-measure: 0.815

===> Train Module: SGDC_SVM

The number of anomaly logs is 6663, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.059663

There are 395 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: SGDC_SVM

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.003378

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed test data summary ======
Test data shape: 27-by-2000

Train validation:
Precision: 0.919, recall: 0.893, F1-measure: 0.906

Test validation:
Precision: 0.846, recall: 0.917, F1-measure: 0.880

===> Train Module: SGDC_LR

The number of anomaly logs is 6663, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.061628

There are 395 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: SGDC_LR

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001995

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed test data summary ======
Test data shape: 27-by-2000

Train validation:
Precision: 0.891, recall: 0.934, F1-measure: 0.912

Test validation:
Precision: 0.846, recall: 0.917, F1-measure: 0.880

===> Predict Model: MultinomialNB.onnx

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.034510

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Test validation:
Precision: 0.928, recall: 0.919, F1-measure: 0.923

===> Predict Model: Perceptron.onnx

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.036100

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Test validation:
Precision: 0.885, recall: 0.877, F1-measure: 0.881

===> Predict Model: SGDC_SVM.onnx

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.034706

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Test validation:
Precision: 0.926, recall: 0.892, F1-measure: 0.909

===> Predict Model: SGDC_LR.onnx

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.034960

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Test validation:
Precision: 0.896, recall: 0.946, F1-measure: 0.920

Pre-processing the raw train dataset ...
Purge costs 0:00:00.098784

===> Train Module: MultinomialNB

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
11 new template IDs are inserted to STIDLE.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.002303

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: MultinomialNB

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.033679

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 0.917, recall: 0.917, F1-measure: 0.917

Test validation:
Precision: 0.931, recall: 0.944, F1-measure: 0.938

===> Train Module: Perceptron

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
0 new template IDs are inserted to STIDLE.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.002096

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: Perceptron

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.034450

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 0.750, recall: 1.000, F1-measure: 0.857

Test validation:
Precision: 0.853, recall: 0.857, F1-measure: 0.855

===> Train Module: SGDC_SVM

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
0 new template IDs are inserted to STIDLE.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.002029

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: SGDC_SVM

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.034057

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 1.000, recall: 0.917, F1-measure: 0.957

Test validation:
Precision: 0.954, recall: 0.892, F1-measure: 0.922

===> Train Module: SGDC_LR

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
0 new template IDs are inserted to STIDLE.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.002275

There are 250 log events
Among all instances, 12 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: SGDC_LR

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.033586

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 0.857, recall: 1.000, F1-measure: 0.923

Test validation:
Precision: 0.900, recall: 0.930, F1-measure: 0.915

===> Predict Model: MultinomialNB.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.364661

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 1.000, recall: 0.040, F1-measure: 0.076

===> Predict Model: Perceptron.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.361765

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 0.973, recall: 0.428, F1-measure: 0.594

===> Predict Model: SGDC_SVM.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.359137

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 0.999, recall: 0.395, F1-measure: 0.566

===> Predict Model: SGDC_LR.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.366033

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 0.986, recall: 0.325, F1-measure: 0.489

Parsing done. [Time taken: 0:00:08.342947]

===> Train Module: MultinomialNB

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
12 new template IDs are inserted to STIDLE.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.368600

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: MultinomialNB

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.033739

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 0.980, recall: 1.000, F1-measure: 0.990

Test validation:
Precision: 0.850, recall: 0.964, F1-measure: 0.903

===> Train Module: Perceptron

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
0 new template IDs are inserted to STIDLE.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.371825

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: Perceptron

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.033068

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 0.998, recall: 1.000, F1-measure: 0.999

Test validation:
Precision: 0.825, recall: 0.953, F1-measure: 0.884

===> Train Module: SGDC_SVM

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
0 new template IDs are inserted to STIDLE.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.374990

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: SGDC_SVM

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.034084

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 1.000, recall: 0.980, F1-measure: 0.990

Test validation:
Precision: 0.928, recall: 0.899, F1-measure: 0.913

===> Train Module: SGDC_LR

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
0 new template IDs are inserted to STIDLE.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.381368

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: SGDC_LR

The number of anomaly logs is 2735, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 759 instances (sliding windows) in this dataset, cost 0:00:00.033587

There are 353 log events
Among all instances, 446 are anomalies
====== Transformed test data summary ======
Test data shape: 759-by-2000

Train validation:
Precision: 0.999, recall: 0.998, F1-measure: 0.999

Test validation:
Precision: 0.851, recall: 0.957, F1-measure: 0.901

===> Predict Model: MultinomialNB.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.403029

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 0.980, recall: 1.000, F1-measure: 0.990

===> Predict Model: Perceptron.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.393172

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 0.998, recall: 1.000, F1-measure: 0.999

===> Predict Model: SGDC_SVM.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.366510

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 1.000, recall: 0.980, F1-measure: 0.990

===> Predict Model: SGDC_LR.onnx

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list in templates: incremental update version.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.363635

There are 176 log events
Among all instances, 2658 are anomalies
====== Transformed test data summary ======
Test data shape: 5664-by-2000

Test validation:
Precision: 0.999, recall: 0.998, F1-measure: 0.999


==============================DeepLog================================

---------epoch=1, hidden=64, win=10-----------
===> Start training the execution path model ...
Slicing the multi-session logs with window 10 ...
Epoch 1/1, train loss: 2.34789
Train Dataset Validation ==> TP: 0, FP: 7827, TN: 196515, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 503, FP: 372, TN: 803, FN: 4
Test Dataset Validation  ==> Precision: 57.49%, Recall: 99.21%, F1: 72.79%

---------epoch=1, hidden=128, win=10-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/1, train loss: 1.42619
Train Dataset Validation ==> TP: 0, FP: 2034, TN: 202308, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 503, FP: 313, TN: 862, FN: 4
Test Dataset Validation  ==> Precision: 61.64%, Recall: 99.21%, F1: 76.04%

---------epoch=1, hidden=256, win=10-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/1, train loss: 0.86946
Train Dataset Validation ==> TP: 0, FP: 973, TN: 203369, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 500, FP: 320, TN: 855, FN: 7
Test Dataset Validation  ==> Precision: 60.98%, Recall: 98.62%, F1: 75.36%

---------epoch=1, hidden=512, win=10-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/1, train loss: 0.67083
Train Dataset Validation ==> TP: 0, FP: 538, TN: 203804, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 500, FP: 299, TN: 876, FN: 7
Test Dataset Validation  ==> Precision: 62.58%, Recall: 98.62%, F1: 76.57%

---------epoch=10, hidden=256, win=10-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/10, train loss: 0.86775
Epoch 2/10, train loss: 0.28339
Epoch 3/10, train loss: 0.24785
Epoch 4/10, train loss: 0.23422
Epoch 5/10, train loss: 0.22111
Epoch 6/10, train loss: 0.21773
Epoch 7/10, train loss: 0.21918
Epoch 8/10, train loss: 0.21071
Epoch 9/10, train loss: 0.21315
Epoch 10/10, train loss: 0.20986
Train Dataset Validation ==> TP: 0, FP: 62, TN: 204280, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 501, FP: 299, TN: 876, FN: 6
Test Dataset Validation  ==> Precision: 62.62%, Recall: 98.82%, F1: 76.66%

---------epoch=40, hidden=512, win=10-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/40, train loss: 0.63961
Epoch 2/40, train loss: 0.27082
Epoch 3/40, train loss: 0.25060
...
Epoch 38/40, train loss: 0.18637
Epoch 39/40, train loss: 0.17900
Epoch 40/40, train loss: 0.18091
Train Dataset Validation ==> TP: 0, FP: 63, TN: 204279, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 609, FP: 182, TN: 840, FN: 51
Test Dataset Validation  ==> Precision: 76.99%, Recall: 92.27%, F1: 83.94%


---------nolog4, epoch=10, hidden=64, win=10-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/10, train loss: 3.98030
Epoch 2/10, train loss: 1.92238
...
Epoch 8/10, train loss: 0.48058
Epoch 9/10, train loss: 0.43728
Epoch 10/10, train loss: 0.40217
Train Dataset Validation ==> TP: 0, FP: 800, TN: 71669, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 611, FP: 335, TN: 687, FN: 49
Test Dataset Validation  ==> Precision: 64.59%, Recall: 92.58%, F1: 76.09%

---------nolog4, epoch=10, hidden=64, win=15-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/10, train loss: 3.71009
Epoch 2/10, train loss: 1.55895
Epoch 3/10, train loss: 0.96212
...
Epoch 8/10, train loss: 0.35984
Epoch 9/10, train loss: 0.32663
Epoch 10/10, train loss: 0.30823
Train Dataset Validation ==> TP: 0, FP: 414, TN: 71105, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 623, FP: 308, TN: 669, FN: 72
Test Dataset Validation  ==> Precision: 66.92%, Recall: 89.64%, F1: 76.63%

---------nolog4, epoch=20, hidden=64, win=15-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/20, train loss: 3.90634
Epoch 2/20, train loss: 1.69969
Epoch 3/20, train loss: 1.01466
Epoch 4/20, train loss: 0.72672
Epoch 5/20, train loss: 0.57623
...
Epoch 18/20, train loss: 0.20537
Epoch 19/20, train loss: 0.20059
Epoch 20/20, train loss: 0.19415
Train Dataset Validation ==> TP: 0, FP: 119, TN: 71400, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 635, FP: 308, TN: 669, FN: 60
Test Dataset Validation  ==> Precision: 67.34%, Recall: 91.37%, F1: 77.53%

---------nolog4, epoch=50, hidden=64, win=15-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/50, train loss: 3.93942
Epoch 2/50, train loss: 1.77968
Epoch 3/50, train loss: 1.03055
Epoch 4/50, train loss: 0.71584
Epoch 5/50, train loss: 0.56388
...
Epoch 48/50, train loss: 0.14578
Epoch 49/50, train loss: 0.13888
Epoch 50/50, train loss: 0.14092
Train Dataset Validation ==> TP: 0, FP: 24, TN: 71495, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 637, FP: 295, TN: 682, FN: 58
Test Dataset Validation  ==> Precision: 68.35%, Recall: 91.65%, F1: 78.30%

---------nolog4, epoch=50, hidden=128, win=15-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/50, train loss: 2.62818
Epoch 2/50, train loss: 0.78153
Epoch 3/50, train loss: 0.45300
Epoch 4/50, train loss: 0.34277
Epoch 5/50, train loss: 0.27756
...
Epoch 48/50, train loss: 0.14064
Epoch 49/50, train loss: 0.13132
Epoch 50/50, train loss: 0.13795
Train Dataset Validation ==> TP: 0, FP: 10, TN: 71509, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 648, FP: 285, TN: 692, FN: 47
Test Dataset Validation  ==> Precision: 69.45%, Recall: 93.24%, F1: 79.61%

---------epoch=300, hidden=128, win=15-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/300, train loss: 2.75612
Epoch 2/300, train loss: 0.86305
Epoch 3/300, train loss: 0.50623
Epoch 4/300, train loss: 0.37446
...
Epoch 50/300, train loss: 0.12838
Epoch 51/300, train loss: 0.12882
Epoch 52/300, train loss: 0.13361
Epoch 53/300, train loss: 0.12697
...
Epoch 100/300, train loss: 0.11384
Epoch 101/300, train loss: 0.11622
Epoch 130/300, train loss: 0.11297
Epoch 131/300, train loss: 0.11060
...
Epoch 198/300, train loss: 0.11563
Epoch 199/300, train loss: 0.11771
Epoch 200/300, train loss: 0.12417
...
Epoch 299/300, train loss: 0.14052
Epoch 300/300, train loss: 0.13801
Train Dataset Validation ==> TP: 0, FP: 58, TN: 72653, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 645, FP: 182, TN: 795, FN: 50
Test Dataset Validation  ==> Precision: 77.99%, Recall: 92.81%, F1: 84.76%


---------epoch=50, hidden=128, win=15, normal_0/1/2-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/50, train loss: 5.07849
Epoch 2/50, train loss: 4.08859
Epoch 3/50, train loss: 3.58933
Epoch 4/50, train loss: 3.18508
Epoch 49/50, train loss: 0.30498
Epoch 50/50, train loss: 0.26244
Train Dataset Validation ==> TP: 0, FP: 0, TN: 5197, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 618, FP: 184, TN: 793, FN: 77
Test Dataset Validation  ==> Precision: 77.06%, Recall: 88.92%, F1: 82.57%

---------epoch=50, hidden=64, win=15, normal_0/1/2-----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/50, train loss: 5.33145
Epoch 2/50, train loss: 4.57109
...
Epoch 49/50, train loss: 0.57072
Epoch 50/50, train loss: 0.68493
Train Dataset Validation ==> TP: 0, FP: 16, TN: 5181, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 625, FP: 205, TN: 772, FN: 70
Test Dataset Validation  ==> Precision: 75.30%, Recall: 89.93%, F1: 81.97%

--------epoch=100, hidden=128, win=15------------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Epoch 1/100, train loss: 2.71784
Epoch 2/100, train loss: 0.86354
...
Epoch 50/100, train loss: 0.12852
Epoch 51/100, train loss: 0.13469
...
Epoch 98/100, train loss: 0.12057
Epoch 99/100, train loss: 0.12173
Epoch 100/100, train loss: 0.11765
Train Dataset Validation ==> TP: 0, FP: 1, TN: 72710, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 640, FP: 179, TN: 798, FN: 55
Test Dataset Validation  ==> Precision: 78.14%, Recall: 92.09%, F1: 84.54%

--------epoch=100, hidden=128, win=10----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/100, train loss: 2.84791
Epoch 2/100, train loss: 0.88179
...
Epoch 50/100, train loss: 0.15823
Epoch 51/100, train loss: 0.16300
...
Epoch 99/100, train loss: 0.15520
Epoch 100/100, train loss: 0.15158
Train Dataset Validation ==> TP: 0, FP: 40, TN: 73636, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 611, FP: 211, TN: 811, FN: 49
Test Dataset Validation  ==> Precision: 74.33%, Recall: 92.58%, F1: 82.46%

--------epoch=200, hidden=128, win=10----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/200, train loss: 2.81116
Epoch 2/200, train loss: 0.91773
...
Epoch 50/200, train loss: 0.16097
Epoch 51/200, train loss: 0.16225
...
Epoch 100/200, train loss: 0.15224
...
Epoch 199/200, train loss: 0.16769
Epoch 200/200, train loss: 0.15647
Train Dataset Validation ==> TP: 0, FP: 14, TN: 73662, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 616, FP: 196, TN: 826, FN: 44
Test Dataset Validation  ==> Precision: 75.86%, Recall: 93.33%, F1: 83.70%
--------epoch=150, hidden=128, win=15----------
Epoch 100/100, train loss: 0.11765
Train Dataset Validation ==> TP: 0, FP: 0, TN: 72710, FN: 0


--------epoch=300, hidden=128, win=10----------

===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/300, train loss: 2.76781
Epoch 2/300, train loss: 0.84473
...
Epoch 100/300, train loss: 0.14799
Epoch 101/300, train loss: 0.14049
Epoch 102/300, train loss: 0.14676
...
Epoch 199/300, train loss: 0.14147
Epoch 200/300, train loss: 0.14472
Epoch 201/300, train loss: 0.16890
Epoch 202/300, train loss: 0.16090
...
Epoch 298/300, train loss: 0.14741
Epoch 299/300, train loss: 0.14518
Epoch 300/300, train loss: 0.14628
Train Dataset Validation ==> TP: 0, FP: 9, TN: 73667, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 611, FP: 214, TN: 808, FN: 49
Test Dataset Validation  ==> Precision: 74.06%, Recall: 92.58%, F1: 82.29%

--------epoch=150, hidden=128, win=15, new session----------
===> Start training the execution path model ...
Slicing the multi-session logs with window 15 ...
Epoch 1/150, train loss: 2.58557
Epoch 2/150, train loss: 0.63773
Epoch 3/150, train loss: 0.37888
Epoch 4/150, train loss: 0.29071
Epoch 5/150, train loss: 0.24456
...
Epoch 100/150, train loss: 0.12241
Epoch 101/150, train loss: 0.10721
...
Epoch 148/150, train loss: 0.10972
Epoch 149/150, train loss: 0.11902
Epoch 150/150, train loss: 0.11131
Train Dataset Validation ==> TP: 0, FP: 1, TN: 77930, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 630, FP: 218, TN: 759, FN: 65
Test Dataset Validation  ==> Precision: 74.29%, Recall: 90.65%, F1: 81.66%

--------epoch=350, hidden=128, win=10, new session----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/350, train loss: 2.56332
Epoch 2/350, train loss: 0.64688
Epoch 3/350, train loss: 0.40092
Epoch 4/350, train loss: 0.32087
Epoch 5/350, train loss: 0.27886
...
Epoch 20/350, train loss: 0.16600
Epoch 21/350, train loss: 0.16197
...
Epoch 100/350, train loss: 0.14682
Epoch 101/350, train loss: 0.13525
...
Epoch 201/350, train loss: 0.14616
Epoch 202/350, train loss: 0.13228
Epoch 203/350, train loss: 0.14033
...
Epoch 300/350, train loss: 0.15511
Epoch 301/350, train loss: 0.13880
...
Epoch 349/350, train loss: 0.15398
Epoch 350/350, train loss: 0.16434
Train Dataset Validation ==> TP: 0, FP: 1, TN: 78895, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 604, FP: 211, TN: 811, FN: 56
Test Dataset Validation  ==> Precision: 74.11%, Recall: 91.52%, F1: 81.90%

--------2020/9/3
--------epoch=150, hidden=128, win=15----------

===> Start training the execution path model ...
Slicing the multi-session logs with window 15 ...
Epoch 1/150, train loss: 2.64648
Epoch 2/150, train loss: 0.66544
Epoch 3/150, train loss: 0.38238
Epoch 4/150, train loss: 0.28404
Epoch 5/150, train loss: 0.23693
...
Epoch 98/150, train loss: 0.11893
Epoch 99/150, train loss: 0.11366
Epoch 100/150, train loss: 0.12355
Epoch 101/150, train loss: 0.11514
...
Epoch 149/150, train loss: 0.12216
Epoch 150/150, train loss: 0.12038
Train Dataset Validation ==> TP: 0, FP: 2, TN: 78297, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 642, FP: 202, TN: 792, FN: 62
Test Dataset Validation  ==> Precision: 76.07%, Recall: 91.19%, F1: 82.95%

--------epoch=350, hidden=128, win=10----------

===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/350, train loss: 2.81230
Epoch 2/350, train loss: 0.82248
Epoch 3/350, train loss: 0.47010
...
Epoch 100/350, train loss: 0.12072
Epoch 101/350, train loss: 0.11598
...
Epoch 150/350, train loss: 0.11593
Epoch 151/350, train loss: 0.12074
...
Epoch 200/350, train loss: 0.11766
Epoch 201/350, train loss: 0.14638
Epoch 202/350, train loss: 0.13828
...
Epoch 250/350, train loss: 0.12179
Epoch 251/350, train loss: 0.11589
...
Epoch 300/350, train loss: 0.11369
Epoch 301/350, train loss: 0.11777
...
Epoch 349/350, train loss: 0.13157
Epoch 350/350, train loss: 0.12317
Train Dataset Validation ==> TP: 0, FP: 8, TN: 79256, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 588, FP: 209, TN: 830, FN: 81
Test Dataset Validation  ==> Precision: 73.78%, Recall: 87.89%, F1: 80.22%

--------epoch=150, hidden=128, win=10----------

===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/150, train loss: 2.88159
Epoch 2/150, train loss: 0.88130
Epoch 3/150, train loss: 0.47410
...
Epoch 99/150, train loss: 0.12065
Epoch 100/150, train loss: 0.12359
...
Epoch 148/150, train loss: 0.12027
Epoch 149/150, train loss: 0.11803
Epoch 150/150, train loss: 0.11862
Train Dataset Validation ==> TP: 0, FP: 4, TN: 79260, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 600, FP: 234, TN: 805, FN: 69
Test Dataset Validation  ==> Precision: 71.94%, Recall: 89.69%, F1: 79.84%

--------epoch=150, hidden=128, win=15, new templates----------
===> Start training the execution path model ...
Slicing the multi-session logs with window 15 ...
Epoch 1/150, train loss: 2.54350
Epoch 2/150, train loss: 0.59760
Epoch 3/150, train loss: 0.36080
...
Epoch 99/150, train loss: 0.11755
Epoch 100/150, train loss: 0.11758
...
Epoch 149/150, train loss: 0.11999
Epoch 150/150, train loss: 0.11423
Train Dataset Validation ==> TP: 0, FP: 6, TN: 78293, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 643, FP: 206, TN: 788, FN: 61
Test Dataset Validation  ==> Precision: 75.74%, Recall: 91.34%, F1: 82.81%

--------epoch=150, hidden=128, win=10, new templates----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/150, train loss: 2.59169
Epoch 2/150, train loss: 0.65219
Epoch 3/150, train loss: 0.39640
Epoch 4/150, train loss: 0.30403
Epoch 5/150, train loss: 0.25871
...
Epoch 99/150, train loss: 0.12786
Epoch 100/150, train loss: 0.12716
Epoch 101/150, train loss: 0.13106
...
Epoch 149/150, train loss: 0.12431
Epoch 150/150, train loss: 0.13312
Train Dataset Validation ==> TP: 0, FP: 0, TN: 79264, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 606, FP: 213, TN: 826, FN: 63
Test Dataset Validation  ==> Precision: 73.99%, Recall: 90.58%, F1: 81.45%

---2020/09/15-----epoch=150, hidden=128, win=15, new templates----------
===> Start training the execution path model ...
Slicing the multi-session logs with window 15 ...
Epoch 1/150, train loss: 2.23680
Epoch 2/150, train loss: 0.52090
Epoch 3/150, train loss: 0.32288
...
Epoch 99/150, train loss: 0.11875
Epoch 100/150, train loss: 0.11905
...
Epoch 149/150, train loss: 0.12040
Epoch 150/150, train loss: 0.11495
Train Dataset Validation ==> TP: 0, FP: 5, TN: 96890, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
Test Dataset Validation  ==> TP: 631, FP: 201, TN: 793, FN: 73
Test Dataset Validation  ==> Precision: 75.84%, Recall: 89.63%, F1: 82.16%

---2020/09/15-----epoch=150, hidden=128, win=10, new templates----------
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Epoch 1/150, train loss: 2.19489
Epoch 2/150, train loss: 0.51872
Epoch 3/150, train loss: 0.32962
...
Epoch 98/150, train loss: 0.12633
Epoch 99/150, train loss: 0.13134
Epoch 100/150, train loss: 0.12714
...
Epoch 148/150, train loss: 0.12789
Epoch 149/150, train loss: 0.12301
Epoch 150/150, train loss: 0.12789
Train Dataset Validation ==> TP: 0, FP: 2, TN: 98038, FN: 0
===> Start evaluating the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
Test Dataset Validation  ==> TP: 615, FP: 217, TN: 822, FN: 54
Test Dataset Validation  ==> Precision: 73.92%, Recall: 91.93%, F1: 81.95%


--------------v2.0.0, 10/17/2021-------------

Loglizer:

===> Train Model: DT

The number of anomaly logs is 11474, but it requires further processing
There are 9155 instances (sliding windows) in this dataset, cost 0:00:00.402512.

There are 406 log events
Among all instances, 3679 are anomalies
====== Transformed train data summary ======
Final train data shape: 9155-by-869

Normal training...: DT

Train validation:
Precision: 0.998, recall: 0.999, F1-measure: 0.999

===> Train Model: LR

The number of anomaly logs is 11474, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 9155 instances (sliding windows) in this dataset, cost 0:00:00.408505.

There are 406 log events
Among all instances, 3679 are anomalies
====== Transformed train data summary ======
Final train data shape: 9155-by-869

Normal training...: LR

Train validation:
Precision: 0.996, recall: 0.997, F1-measure: 0.996

===> Train Model: SVM

The number of anomaly logs is 11474, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 9155 instances (sliding windows) in this dataset, cost 0:00:00.406627.

There are 406 log events
Among all instances, 3679 are anomalies
====== Transformed train data summary ======
Final train data shape: 9155-by-869

Normal training...: SVM

Train validation:
Precision: 0.995, recall: 0.996, F1-measure: 0.996

===> Train Model: RFC

The number of anomaly logs is 11474, but it requires further processing
Loading shuffled EventId list in templates: static version.
There are 9155 instances (sliding windows) in this dataset, cost 0:00:00.445183.

There are 406 log events
Among all instances, 3679 are anomalies
====== Transformed train data summary ======
Final train data shape: 9155-by-869

Normal training...: RFC

Train validation:
Precision: 0.998, recall: 0.999, F1-measure: 0.999


===> Train Model: MNB

The number of anomaly logs is 6649, but it requires further processing
Building shuffled EventId list of templates.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.041953.

There are 386 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: MNB

Train validation:
Precision: 0.918, recall: 0.922, F1-measure: 0.920

===> Train Model: PTN

The number of anomaly logs is 6649, but it requires further processing
Loading shuffled EventId list of templates.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.041942.

There are 386 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: PTN

Train validation:
Precision: 0.777, recall: 0.941, F1-measure: 0.851

===> Train Model: SGDC_SVM

The number of anomaly logs is 6649, but it requires further processing
Loading shuffled EventId list of templates.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.042135.

There are 386 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: SGDC_SVM

Train validation:
Precision: 0.826, recall: 0.908, F1-measure: 0.865

===> Train Model: SGDC_LR

The number of anomaly logs is 6649, but it requires further processing
Loading shuffled EventId list of templates.
There are 1217 instances (sliding windows) in this dataset, cost 0:00:00.042872.

There are 386 log events
Among all instances, 683 are anomalies
====== Transformed train data summary ======
Final train data shape: 1217-by-2000

First time training...: SGDC_LR

Train validation:
Precision: 0.890, recall: 0.857, F1-measure: 0.873


===> Train Model: MNB

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list of templates.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001443.

There are 249 log events
Among all instances, 13 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: MNB

Train validation:
Precision: 0.923, recall: 0.923, F1-measure: 0.923

===> Train Model: PTN

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list of templates.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001470.

There are 249 log events
Among all instances, 13 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: PTN

Train validation:
Precision: 1.000, recall: 0.923, F1-measure: 0.960

===> Train Model: SGDC_SVM

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list of templates.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001556.

There are 249 log events
Among all instances, 13 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: SGDC_SVM

Train validation:
Precision: 0.867, recall: 1.000, F1-measure: 0.929

===> Train Model: SGDC_LR

The number of anomaly logs is 516, but it requires further processing
Loading shuffled EventId list of templates.
There are 27 instances (sliding windows) in this dataset, cost 0:00:00.001499.

There are 249 log events
Among all instances, 13 are anomalies
====== Transformed train data summary ======
Final train data shape: 27-by-2000

Incremental training...: SGDC_LR

Train validation:
Precision: 1.000, recall: 0.923, F1-measure: 0.960


===> Train Model: MNB

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list of templates.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.274560.

There are 178 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: MNB

Train validation:
Precision: 0.981, recall: 1.000, F1-measure: 0.990

===> Train Model: PTN

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list of templates.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.274985.

There are 178 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: PTN

Train validation:
Precision: 0.998, recall: 0.999, F1-measure: 0.999

===> Train Model: SGDC_SVM

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list of templates.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.255109.

There are 178 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: SGDC_SVM

Train validation:
Precision: 0.998, recall: 0.998, F1-measure: 0.998

===> Train Model: SGDC_LR

The number of anomaly logs is 2633, but it requires further processing
Loading shuffled EventId list of templates.
There are 5664 instances (sliding windows) in this dataset, cost 0:00:00.265383.

There are 178 log events
Among all instances, 2658 are anomalies
====== Transformed train data summary ======
Final train data shape: 5664-by-2000

Incremental training...: SGDC_LR

Train validation:
Precision: 0.998, recall: 1.000, F1-measure: 0.999


===> Train Model: MNB

The number of anomaly logs is 1676, but it requires further processing
Loading shuffled EventId list of templates.
There are 2244 instances (sliding windows) in this dataset, cost 0:00:00.119249.

There are 208 log events
Among all instances, 323 are anomalies
====== Transformed train data summary ======
Final train data shape: 2244-by-2000

Incremental training...: MNB

Train validation:
Precision: 0.705, recall: 1.000, F1-measure: 0.827

===> Train Model: PTN

The number of anomaly logs is 1676, but it requires further processing
Loading shuffled EventId list of templates.
There are 2244 instances (sliding windows) in this dataset, cost 0:00:00.114642.

There are 208 log events
Among all instances, 323 are anomalies
====== Transformed train data summary ======
Final train data shape: 2244-by-2000

Incremental training...: PTN

Train validation:
Precision: 1.000, recall: 1.000, F1-measure: 1.000

===> Train Model: SGDC_SVM

The number of anomaly logs is 1676, but it requires further processing
Loading shuffled EventId list of templates.
There are 2244 instances (sliding windows) in this dataset, cost 0:00:00.114327.

There are 208 log events
Among all instances, 323 are anomalies
====== Transformed train data summary ======
Final train data shape: 2244-by-2000

Incremental training...: SGDC_SVM

Train validation:
Precision: 0.994, recall: 1.000, F1-measure: 0.997

===> Train Model: SGDC_LR

The number of anomaly logs is 1676, but it requires further processing
Loading shuffled EventId list of templates.
There are 2244 instances (sliding windows) in this dataset, cost 0:00:00.114115.

There are 208 log events
Among all instances, 323 are anomalies
====== Transformed train data summary ======
Final train data shape: 2244-by-2000

Incremental training...: SGDC_LR

Train validation:
Precision: 1.000, recall: 1.000, F1-measure: 1.000

DeepLog:

===> Start training the execution path model ...
Building shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
100% 3732/3732 [01:53<00:00, 32.80Batches/s]
Epoch 1/150, train loss: 2.07581
100% 3732/3732 [01:52<00:00, 33.32Batches/s]
Epoch 2/150, train loss: 0.53035
...
100% 3732/3732 [02:44<00:00, 22.73Batches/s]
Epoch 149/150, train loss: 0.20911
100% 3732/3732 [03:13<00:00, 19.27Batches/s]
Epoch 150/150, train loss: 0.24225
100% 3732/3732 [00:59<00:00, 62.48Batches/s]
Train Dataset Validation ==> TP: 0, FP: 76, TN: 119327, FN: 0

===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
100% 3774/3774 [01:48<00:00, 34.78Batches/s]
Epoch 1/150, train loss: 2.15389
100% 3774/3774 [01:41<00:00, 37.30Batches/s]
Epoch 2/150, train loss: 0.57234
...
100% 3774/3774 [01:39<00:00, 38.12Batches/s]
Epoch 147/150, train loss: 0.16597
100% 3774/3774 [01:39<00:00, 37.85Batches/s]
Epoch 148/150, train loss: 0.16017
100% 3774/3774 [01:39<00:00, 37.75Batches/s]
Epoch 149/150, train loss: 0.15923
100% 3774/3774 [01:40<00:00, 37.44Batches/s]
Epoch 150/150, train loss: 0.16598
100% 3774/3774 [00:44<00:00, 84.03Batches/s]
Train Dataset Validation ==> TP: 0, FP: 32, TN: 120711, FN: 0


--------------v2.0.0, 10/17/2021-------------

commit e131d4a5
---------------
DeepLog:

===> Start training the execution path model ...
Building shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
100% 3773/3773 [02:02<00:00, 30.84Batches/s]
Epoch 1/150, train loss: 2.02911
100% 3773/3773 [02:01<00:00, 30.99Batches/s]
Epoch 2/150, train loss: 0.48611
100% 3773/3773 [02:04<00:00, 30.36Batches/s]
Epoch 3/150, train loss: 0.32713
...
Epoch 100/150, train loss: 0.12688
100% 3773/3773 [02:04<00:00, 30.26Batches/s]
Epoch 101/150, train loss: 0.12225
100% 3773/3773 [02:06<00:00, 29.81Batches/s]
...
100% 3773/3773 [02:02<00:00, 30.73Batches/s]
Epoch 150/150, train loss: 0.14006
100% 3773/3773 [00:49<00:00, 76.89Batches/s]
Train Dataset Validation ==> TP: 0, FP: 33, TN: 120682, FN: 0

===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
100% 3815/3815 [01:35<00:00, 39.88Batches/s]
Epoch 1/150, train loss: 2.21747
100% 3815/3815 [01:35<00:00, 39.85Batches/s]
Epoch 2/150, train loss: 0.59904
100% 3815/3815 [01:36<00:00, 39.45Batches/s]
Epoch 3/150, train loss: 0.40019
...
100% 3815/3815 [01:37<00:00, 39.19Batches/s]
Epoch 100/150, train loss: 0.13910
100% 3815/3815 [01:38<00:00, 38.75Batches/s]
Epoch 101/150, train loss: 0.14365
...
100% 3815/3815 [01:39<00:00, 38.38Batches/s]
Epoch 149/150, train loss: 0.14719
100% 3815/3815 [01:40<00:00, 38.08Batches/s]
Epoch 150/150, train loss: 0.15002
100% 3815/3815 [00:44<00:00, 86.22Batches/s]
Train Dataset Validation ==> TP: 0, FP: 7, TN: 122048, FN: 0

--------------v2.0.0, 11/22/2021-------------

-------one-hot vector--------
DeepLog:
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
100% 3773/3773 [01:39<00:00, 38.07Batches/s]
Epoch 1/5, train loss: 2.38774
100% 3773/3773 [01:40<00:00, 37.70Batches/s]
Epoch 2/5, train loss: 0.56789
100% 3773/3773 [01:41<00:00, 37.32Batches/s]
Epoch 3/5, train loss: 0.30855
100% 3773/3773 [01:39<00:00, 37.81Batches/s]
Epoch 4/5, train loss: 0.21873
100% 3773/3773 [01:41<00:00, 37.35Batches/s]
Epoch 5/5, train loss: 0.17918
100% 3773/3773 [00:37<00:00, 100.38Batches/s]
Train Dataset Validation ==> TP: 0, FP: 80, TN: 120635, FN: 0

-------index in vocab--------
DeepLog:
===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
100% 3773/3773 [01:53<00:00, 33.16Batches/s]
Epoch 1/5, train loss: 2.22002
100% 3773/3773 [01:52<00:00, 33.60Batches/s]
Epoch 2/5, train loss: 0.54866
100% 3773/3773 [01:53<00:00, 33.12Batches/s]
Epoch 3/5, train loss: 0.35657
100% 3773/3773 [01:53<00:00, 33.27Batches/s]
Epoch 4/5, train loss: 0.28468
100% 3773/3773 [01:54<00:00, 32.86Batches/s]
Epoch 5/5, train loss: 0.24762
100% 3773/3773 [00:47<00:00, 79.41Batches/s]
Train Dataset Validation ==> TP: 0, FP: 491, TN: 120224, FN: 0

--------------v2.0.0, 11/23/2021-------------

-------one-hot vector--------
===> Start training the execution path model ...
Building shuffled EventId list of templates.
Slicing the multi-session logs with window 15 ...
100% 3773/3773 [05:11<00:00, 12.13Batches/s]
Epoch 1/100, train loss: 2.32570
100% 3773/3773 [03:10<00:00, 19.76Batches/s]
Epoch 2/100, train loss: 0.57237
100% 3773/3773 [03:19<00:00, 18.94Batches/s]
Epoch 3/100, train loss: 0.32451
100% 3773/3773 [03:13<00:00, 19.47Batches/s]
Epoch 4/100, train loss: 0.22889
100% 3773/3773 [03:51<00:00, 16.29Batches/s]
Epoch 5/100, train loss: 0.18498
...
100% 3773/3773 [02:29<00:00, 25.15Batches/s]
Epoch 50/100, train loss: 0.07544
100% 3773/3773 [02:16<00:00, 27.57Batches/s]
Epoch 51/100, train loss: 0.07464
100% 3773/3773 [02:35<00:00, 24.30Batches/s]
Epoch 52/100, train loss: 0.07477
...
100% 3773/3773 [01:47<00:00, 35.16Batches/s]
Epoch 95/100, train loss: 0.06902
100% 3773/3773 [01:47<00:00, 35.12Batches/s]
Epoch 96/100, train loss: 0.06945
100% 3773/3773 [01:48<00:00, 34.87Batches/s]
Epoch 97/100, train loss: 0.07081
100% 3773/3773 [01:50<00:00, 34.19Batches/s]
Epoch 98/100, train loss: 0.06984
100% 3773/3773 [01:49<00:00, 34.47Batches/s]
Epoch 99/100, train loss: 0.06941
100% 3773/3773 [01:49<00:00, 34.36Batches/s]
Epoch 100/100, train loss: 0.07032
Train Dataset Validation ==> TP: 0, FP: 0, TN: 120715, FN: 0

===> Start training the execution path model ...
Loading shuffled EventId list of templates.
Slicing the multi-session logs with window 10 ...
100% 3815/3815 [01:28<00:00, 43.29Batches/s]
Epoch 1/100, train loss: 2.15085
100% 3815/3815 [01:28<00:00, 43.13Batches/s]
Epoch 2/100, train loss: 0.48124
100% 3815/3815 [01:27<00:00, 43.83Batches/s]
Epoch 3/100, train loss: 0.30276
100% 3815/3815 [01:28<00:00, 43.25Batches/s]
Epoch 4/100, train loss: 0.23260
100% 3815/3815 [01:27<00:00, 43.79Batches/s]
Epoch 5/100, train loss: 0.19576
...
100% 3815/3815 [01:29<00:00, 42.81Batches/s]
Epoch 50/100, train loss: 0.09791
100% 3815/3815 [01:29<00:00, 42.51Batches/s]
Epoch 51/100, train loss: 0.09755
100% 3815/3815 [01:27<00:00, 43.62Batches/s]
Epoch 52/100, train loss: 0.09737
...
100% 3815/3815 [01:27<00:00, 43.52Batches/s]
Epoch 95/100, train loss: 0.09218
100% 3815/3815 [01:27<00:00, 43.48Batches/s]
Epoch 96/100, train loss: 0.09238
100% 3815/3815 [01:26<00:00, 44.01Batches/s]
Epoch 97/100, train loss: 0.09213
100% 3815/3815 [01:27<00:00, 43.80Batches/s]
Epoch 98/100, train loss: 0.09315
100% 3815/3815 [01:28<00:00, 43.27Batches/s]
Epoch 99/100, train loss: 0.09236
100% 3815/3815 [01:28<00:00, 43.18Batches/s]
Epoch 100/100, train loss: 0.09224
100% 3815/3815 [00:35<00:00, 107.08Batches/s]
Train Dataset Validation ==> TP: 0, FP: 0, TN: 122055, FN: 0
